{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e45771-67eb-4589-bdf3-fd3156c1c78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py): started\n",
      "  Building wheel for wget (setup.py): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=9d8f05cee65a1fec7461eabd8ff519aecb643b0f2cd447d187ddd1c690f9a6a4\n",
      "  Stored in directory: c:\\users\\gouta\\appdata\\local\\pip\\cache\\wheels\\40\\b3\\0f\\a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a9088f-8223-4d7b-8269-bd50da12f898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german.data'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data'\n",
    "wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c61350b-4f5e-4c8c-b96c-999d043a7ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german.doc'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2= 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.doc'\n",
    "wget.download(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3c34f5e-25c6-414e-ab0e-343df54c1884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aif360\n",
      "  Downloading aif360-0.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from aif360) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from aif360) (1.11.4)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from aif360) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from aif360) (1.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from aif360) (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->aif360) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->aif360) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0->aif360) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0->aif360) (2.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from matplotlib->aif360) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from matplotlib->aif360) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from matplotlib->aif360) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from matplotlib->aif360) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from matplotlib->aif360) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from matplotlib->aif360) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from matplotlib->aif360) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360) (1.16.0)\n",
      "Downloading aif360-0.6.1-py3-none-any.whl (259 kB)\n",
      "   ---------------------------------------- 0.0/259.7 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/259.7 kB ? eta -:--:--\n",
      "   ------ -------------------------------- 41.0/259.7 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  256.0/259.7 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 259.7/259.7 kB 2.7 MB/s eta 0:00:00\n",
      "Installing collected packages: aif360\n",
      "Successfully installed aif360-0.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ea2db6b-4ebb-42a8-b160-fa313ed894da",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Destination path 'C:\\Users\\gouta\\anaconda3\\aif360/data/raw/german/german.data' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Move each file in the list to the destination folder\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m source_files:\n\u001b[1;32m---> 17\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mmove(file, destination_folder)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMoved \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Print success message\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\shutil.py:823\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    820\u001b[0m     real_dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, _basename(src))\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(real_dst):\n\u001b[1;32m--> 823\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDestination path \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m real_dst)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    825\u001b[0m     os\u001b[38;5;241m.\u001b[39mrename(src, real_dst)\n",
      "\u001b[1;31mError\u001b[0m: Destination path 'C:\\Users\\gouta\\anaconda3\\aif360/data/raw/german/german.data' already exists"
     ]
    }
   ],
   "source": [
    "import site\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Get the site-packages location\n",
    "location = site.getsitepackages()[0]\n",
    "\n",
    "# Define source and destination paths\n",
    "source_files = ['german.data', 'german.doc']  # List of files to move\n",
    "destination_folder = os.path.join(location, 'aif360/data/raw/german/')\n",
    "\n",
    "# Ensure the destination folder exists\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Move each file in the list to the destination folder\n",
    "for file in source_files:\n",
    "    shutil.move(file, destination_folder)\n",
    "    print(f\"Moved {file} to {destination_folder}\")\n",
    "\n",
    "# Print success message\n",
    "print(\"All files moved successfully!\")\n",
    "# List files in the current directory to confirm that the source files exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c54acb2f-6815-4063-b811-d575c30adbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the German dataset\n",
    "import numpy as np\n",
    "from aif360.datasets import GermanDataset\n",
    "\n",
    "dataset = GermanDataset(protected_attribute_names=[\"sex\"],\n",
    "privileged_classes=[lambda x: x == \"male\"],\n",
    "features_to_drop=[\"personal_status\", \"age\"]\n",
    ")\n",
    "\n",
    "\n",
    "def convert_to_binary_labels(arr):\n",
    "    \n",
    "    ''' Converts the old target variables to a new binary target, where\n",
    "    0 = The individual is undeserving of credit (bad risk),\n",
    "    1 = Deserving of credit (good risk).\n",
    "    '''\n",
    "    return np.abs(arr - 2)\n",
    "\n",
    "dataset.labels = convert_to_binary_labels(dataset.labels.ravel())\n",
    "# Split the dataset into training and validation sets\n",
    "dataset_train, dataset_val = dataset.split([0.8], shuffle=True, seed=0)\n",
    "# Get features and labels\n",
    "X_train, y_train = dataset_train.features, dataset_train.labels\n",
    "X_val, y_val = dataset_val.features, dataset_val.labels\n",
    "feature_names = dataset_train.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde13157-0613-4d31-8a86-809d54ef2ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "478e4d69-9415-40cb-9b33-ddbd60dc871d",
   "metadata": {},
   "source": [
    "<h2>Exploratory Data Analysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d6f15aa2-a875-4be5-8b0f-a460b9028d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Men: 26 total\n",
      "  Good Credit Risk (1): 88.46% (23 out of 26)\n",
      "  Bad Credit Risk (0): 11.54% (3 out of 26)\n",
      "\n",
      "Women: 774 total\n",
      "  Good Credit Risk (1): 69.77% (540 out of 774)\n",
      "  Bad Credit Risk (0): 30.23% (234 out of 774)\n"
     ]
    }
   ],
   "source": [
    "#Step-1:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_df= pd.DataFrame(data=X_train, columns=feature_names)\n",
    "train_df['sex']= X_train[:,-1] #Last column which is sex\n",
    "train_df['label'] = y_train #Labels\n",
    "\n",
    "#Data by gender\n",
    "men_df = train_df[train_df['sex']==1]\n",
    "women_df = train_df[train_df['sex']==0]\n",
    "\n",
    "total_men= len(men_df)\n",
    "total_women = len(women_df)\n",
    "\n",
    "#Count of good and bad credit for men\n",
    "men_good_credit = len(men_df[men_df['label']==1])\n",
    "men_bad_credit = len(men_df[men_df['label']==0])\n",
    "\n",
    "#Count of good and bad credit for women\n",
    "women_good_credit = len(women_df[women_df['label']==1])\n",
    "women_bad_credit = len(women_df[women_df['label']==0])\n",
    "\n",
    "#Calculation of good and bad credit ratio for Men\n",
    "men_good_credit_ratio = men_good_credit/total_men\n",
    "men_bad_credit_ratio = men_bad_credit/total_men\n",
    "\n",
    "#Calculation of good and bad credit ratio for Women\n",
    "women_good_credit_ratio = women_good_credit/total_women\n",
    "women_bad_credit_ratio = women_bad_credit/total_women\n",
    "\n",
    "\n",
    "print(f\"Men: {total_men} total\")\n",
    "print(f\"  Good Credit Risk (1): {men_good_credit_ratio:.2%} ({men_good_credit} out of {total_men})\")\n",
    "print(f\"  Bad Credit Risk (0): {men_bad_credit_ratio:.2%} ({men_bad_credit} out of {total_men})\")\n",
    "\n",
    "print(f\"\\nWomen: {total_women} total\")\n",
    "print(f\"  Good Credit Risk (1): {women_good_credit_ratio:.2%} ({women_good_credit} out of {total_women})\")\n",
    "print(f\"  Bad Credit Risk (0): {women_bad_credit_ratio:.2%} ({women_bad_credit} out of {total_women})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "36872dea-5f93-4e4c-90d3-e5e82f06aa54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>investment_as_income_percentage</th>\n",
       "      <th>residence_since</th>\n",
       "      <th>number_of_credits</th>\n",
       "      <th>people_liable_for</th>\n",
       "      <th>sex</th>\n",
       "      <th>status=A11</th>\n",
       "      <th>status=A12</th>\n",
       "      <th>status=A13</th>\n",
       "      <th>...</th>\n",
       "      <th>housing=A153</th>\n",
       "      <th>skill_level=A171</th>\n",
       "      <th>skill_level=A172</th>\n",
       "      <th>skill_level=A173</th>\n",
       "      <th>skill_level=A174</th>\n",
       "      <th>telephone=A191</th>\n",
       "      <th>telephone=A192</th>\n",
       "      <th>foreign_worker=A201</th>\n",
       "      <th>foreign_worker=A202</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>3959.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3577.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2515.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>10366.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2132.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1374.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  credit_amount  investment_as_income_percentage  residence_since  \\\n",
       "0     36.0         3959.0                              4.0              3.0   \n",
       "1      9.0         3577.0                              1.0              2.0   \n",
       "2     18.0         2515.0                              3.0              4.0   \n",
       "3     12.0         1995.0                              4.0              1.0   \n",
       "4     60.0        10366.0                              2.0              4.0   \n",
       "..     ...            ...                              ...              ...   \n",
       "795   10.0         2132.0                              2.0              3.0   \n",
       "796   18.0         1950.0                              4.0              1.0   \n",
       "797    6.0         1374.0                              1.0              2.0   \n",
       "798    6.0         1449.0                              1.0              2.0   \n",
       "799   18.0         1582.0                              4.0              4.0   \n",
       "\n",
       "     number_of_credits  people_liable_for  sex  status=A11  status=A12  \\\n",
       "0                  1.0                1.0  0.0         1.0         0.0   \n",
       "1                  1.0                2.0  1.0         0.0         0.0   \n",
       "2                  1.0                1.0  0.0         0.0         0.0   \n",
       "3                  1.0                1.0  0.0         0.0         1.0   \n",
       "4                  1.0                1.0  0.0         0.0         0.0   \n",
       "..                 ...                ...  ...         ...         ...   \n",
       "795                2.0                1.0  1.0         1.0         0.0   \n",
       "796                2.0                1.0  0.0         0.0         0.0   \n",
       "797                1.0                1.0  0.0         1.0         0.0   \n",
       "798                2.0                2.0  0.0         0.0         1.0   \n",
       "799                2.0                1.0  0.0         0.0         0.0   \n",
       "\n",
       "     status=A13  ...  housing=A153  skill_level=A171  skill_level=A172  \\\n",
       "0           0.0  ...           0.0               0.0               0.0   \n",
       "1           0.0  ...           0.0               0.0               0.0   \n",
       "2           0.0  ...           0.0               0.0               0.0   \n",
       "3           0.0  ...           0.0               0.0               0.0   \n",
       "4           0.0  ...           0.0               0.0               0.0   \n",
       "..          ...  ...           ...               ...               ...   \n",
       "795         0.0  ...           0.0               0.0               0.0   \n",
       "796         0.0  ...           0.0               0.0               0.0   \n",
       "797         0.0  ...           0.0               0.0               1.0   \n",
       "798         0.0  ...           0.0               0.0               0.0   \n",
       "799         0.0  ...           0.0               0.0               0.0   \n",
       "\n",
       "     skill_level=A173  skill_level=A174  telephone=A191  telephone=A192  \\\n",
       "0                 0.0               1.0             0.0             1.0   \n",
       "1                 1.0               0.0             1.0             0.0   \n",
       "2                 1.0               0.0             0.0             1.0   \n",
       "3                 1.0               0.0             1.0             0.0   \n",
       "4                 0.0               1.0             0.0             1.0   \n",
       "..                ...               ...             ...             ...   \n",
       "795               1.0               0.0             1.0             0.0   \n",
       "796               1.0               0.0             0.0             1.0   \n",
       "797               0.0               0.0             0.0             1.0   \n",
       "798               1.0               0.0             1.0             0.0   \n",
       "799               1.0               0.0             1.0             0.0   \n",
       "\n",
       "     foreign_worker=A201  foreign_worker=A202  label  \n",
       "0                    1.0                  0.0    1.0  \n",
       "1                    0.0                  1.0    1.0  \n",
       "2                    1.0                  0.0    1.0  \n",
       "3                    1.0                  0.0    1.0  \n",
       "4                    1.0                  0.0    1.0  \n",
       "..                   ...                  ...    ...  \n",
       "795                  0.0                  1.0    1.0  \n",
       "796                  1.0                  0.0    1.0  \n",
       "797                  1.0                  0.0    1.0  \n",
       "798                  1.0                  0.0    1.0  \n",
       "799                  1.0                  0.0    1.0  \n",
       "\n",
       "[800 rows x 58 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5bae3023-bdaf-477a-9134-297a748f508c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: month\n",
      " Correlation with sex: -0.12\n",
      " Correlation with Label: -0.21\n",
      "Feature: credit_amount\n",
      " Correlation with sex: -0.01\n",
      " Correlation with Label: -0.17\n",
      "Feature: investment_as_income_percentage\n",
      " Correlation with sex: -0.11\n",
      " Correlation with Label: -0.06\n"
     ]
    }
   ],
   "source": [
    "#Step-2:\n",
    "\n",
    "selected_features = ['month','credit_amount','investment_as_income_percentage']\n",
    "\n",
    "#Correlation\n",
    "correlations = {}\n",
    "\n",
    "for feature in selected_features:\n",
    "    feature_value = train_df[feature].values\n",
    "\n",
    "    #correlation with sex\n",
    "    sex_value = train_df['sex'].values\n",
    "    correlation_with_sex = np.corrcoef(feature_value, sex_value)[0,1]\n",
    "\n",
    "    #correlation with label\n",
    "    label_value = train_df['label'].values\n",
    "    correlation_with_label = np.corrcoef(feature_value, label_value)[0,1]\n",
    "\n",
    "    correlations[feature]= {'Correlation with Sex': correlation_with_sex, 'Correlation with label': correlation_with_label}\n",
    "\n",
    "for feature, corr_values in correlations.items():\n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(f\" Correlation with sex: {corr_values['Correlation with Sex']: .2f}\")\n",
    "    print(f\" Correlation with Label: {corr_values['Correlation with label']: .2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea95fb7-be02-4075-b295-1b5e90220d1c",
   "metadata": {},
   "source": [
    "<h2>Model Training (LR, Random Forst, XGBoost)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ac2dfbc1-e43f-41ab-8ddc-658513034917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Standardize features to have mean zero and unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train_transformed = scaler.fit_transform(X_train)\n",
    "X_val_transformed = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fee3b4d3-21e0-49e9-9f94-a892d9764697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Best C (hyperparameter): 0.01\n",
      "Logistic Regression Training Accuracy: 0.7738\n",
      "Logistic Regression Validation Accuracy: 0.7500\n",
      "\n",
      "Classification Report (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.24      0.37        63\n",
      "         1.0       0.74      0.99      0.84       137\n",
      "\n",
      "    accuracy                           0.75       200\n",
      "   macro avg       0.81      0.61      0.61       200\n",
      "weighted avg       0.78      0.75      0.70       200\n",
      "\n",
      "Confusion Matrix (Validation Set):\n",
      "[[ 15  48]\n",
      " [  2 135]]\n"
     ]
    }
   ],
   "source": [
    "#Model Training\n",
    "\n",
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Logistic Regression with Cross-Validation\n",
    "hyperparameter = [0.01, 0.1, 1, 10, 100] \n",
    "\n",
    "log_reg_cv = LogisticRegressionCV(\n",
    "    Cs=hyperparameter,           \n",
    "    cv=5,                         \n",
    "    max_iter=1000,          \n",
    "    scoring='accuracy',            \n",
    "    random_state=0           \n",
    ")\n",
    "\n",
    "# Train the Logistic Regression model with cross-validation\n",
    "log_reg_cv.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Best regularization strength (C) chosen by cross-validation\n",
    "optimal_hyperparameter_C = log_reg_cv.C_[0]\n",
    "\n",
    "y_train_pred_lr = log_reg_cv.predict(X_train_transformed)\n",
    "y_val_pred_lr = log_reg_cv.predict(X_val_transformed)\n",
    "\n",
    "train_acc_lr = accuracy_score(y_train, y_train_pred_lr)\n",
    "val_acc_lr = accuracy_score(y_val, y_val_pred_lr)\n",
    "\n",
    "print(f\"Logistic Regression Best C (hyperparameter): {optimal_hyperparameter_C}\")\n",
    "print(f\"Logistic Regression Training Accuracy: {train_acc_lr:.4f}\")\n",
    "print(f\"Logistic Regression Validation Accuracy: {val_acc_lr:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Validation Set):\")\n",
    "print(classification_report(y_val, y_val_pred_lr))\n",
    "\n",
    "print(\"Confusion Matrix (Validation Set):\")\n",
    "print(confusion_matrix(y_val, y_val_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d6fc68-f740-4c8e-bc27-73967fb769ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3c1074ab-abb6-4652-8405-1ff1bf1d08af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Random Forest Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Random Forest Training Accuracy: 0.9025\n",
      "Random Forest Validation Accuracy: 0.7800\n",
      "\n",
      "Classification Report (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.33      0.49        63\n",
      "         1.0       0.76      0.99      0.86       137\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.84      0.66      0.67       200\n",
      "weighted avg       0.81      0.78      0.74       200\n",
      "\n",
      "Confusion Matrix (Validation Set):\n",
      "[[ 21  42]\n",
      " [  2 135]]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparameter = {\n",
    "    'n_estimators': [50, 100, 200],       # Number of trees in the forest\n",
    "    'max_depth': [5, 10, 20],             # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 10],         \n",
    "    'min_samples_leaf': [1, 5]            \n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "grid_search_rf = GridSearchCV(estimator=rf, param_grid=hyperparameter, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search_rf.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Get the best model and best hyperparameters from the GridSearchCV\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "best_rf_params = grid_search_rf.best_params_\n",
    "\n",
    "y_train_pred_rf = best_rf.predict(X_train_transformed)\n",
    "y_val_pred_rf = best_rf.predict(X_val_transformed)\n",
    "\n",
    "train_acc_rf = accuracy_score(y_train, y_train_pred_rf)\n",
    "val_acc_rf = accuracy_score(y_val, y_val_pred_rf)\n",
    "\n",
    "print(f\"Random Forest Best Hyperparameters: {best_rf_params}\")\n",
    "print(f\"Random Forest Training Accuracy: {train_acc_rf:.4f}\")\n",
    "print(f\"Random Forest Validation Accuracy: {val_acc_rf:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Validation Set):\")\n",
    "print(classification_report(y_val, y_val_pred_rf))\n",
    "\n",
    "print(\"Confusion Matrix (Validation Set):\")\n",
    "print(confusion_matrix(y_val, y_val_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5aff534e-574f-4e72-9f1b-055b08f4ffa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "XGBoost Best Hyperparameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      "XGBoost Training Accuracy: 0.8825\n",
      "XGBoost Validation Accuracy: 0.7700\n",
      "\n",
      "Classification Report (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.46      0.56        63\n",
      "         1.0       0.79      0.91      0.84       137\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.75      0.69      0.70       200\n",
      "weighted avg       0.76      0.77      0.75       200\n",
      "\n",
      "Confusion Matrix (Validation Set):\n",
      "[[ 29  34]\n",
      " [ 12 125]]\n"
     ]
    }
   ],
   "source": [
    "#XG Boost\n",
    "import xgboost as xgb\n",
    "\n",
    "hyperparameter = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialization of XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(random_state=0)\n",
    "\n",
    "# Grid Search with 5-fold cross-validation\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=hyperparameter, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search_xgb.fit(X_train_transformed, y_train)\n",
    "\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "best_xgb_params = grid_search_xgb.best_params_\n",
    "\n",
    "y_train_pred_xgb = best_xgb.predict(X_train_transformed)\n",
    "y_val_pred_xgb = best_xgb.predict(X_val_transformed)\n",
    "\n",
    "train_acc_xgb = accuracy_score(y_train, y_train_pred_xgb)\n",
    "val_acc_xgb = accuracy_score(y_val, y_val_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost Best Hyperparameters: {best_xgb_params}\")\n",
    "print(f\"XGBoost Training Accuracy: {train_acc_xgb:.4f}\")\n",
    "print(f\"XGBoost Validation Accuracy: {val_acc_xgb:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report (Validation Set):\")\n",
    "print(classification_report(y_val, y_val_pred_xgb))\n",
    "\n",
    "print(\"Confusion Matrix (Validation Set):\")\n",
    "print(confusion_matrix(y_val, y_val_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8d414b0a-78c2-4e3b-bb3e-8e87419e1687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the validation set with your classifier's predicted labels\n",
    "dataset_val_orig = dataset_val.copy()\n",
    "privileged_classes = [{\"sex\": 1}] # Men (sex = 1)\n",
    "unprivileged_classes = [{\"sex\": 0}] # Women (sex = 0)\n",
    "dataset_val.labels = y_val_pred_rf.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fb1b3d33-1572-4c6a-8701-4e203951b4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Favourable outcomes for unprivileged group (men): 0.8518518518518519\n",
      "Favourable outcomes for privileged group (men): 0.8972602739726028\n",
      "Disparate Impact: 0.9493921402318348\n"
     ]
    }
   ],
   "source": [
    "#Disparate Impact\n",
    "\n",
    "sex_column = dataset_val.features[:,dataset_val.feature_names.index('sex')]\n",
    "\n",
    "privi_grp = (sex_column==1)\n",
    "unprivi_grp= (sex_column==0)\n",
    "\n",
    "p_privi_positive = np.mean(y_val_pred_rf[privi_grp]==1)\n",
    "p_unprivi_positive = np.mean(y_val_pred_rf[unprivi_grp]==1)\n",
    "\n",
    "disparate_impact = p_unprivi_positive/p_privi_positive\n",
    "\n",
    "print(f\"Favourable outcomes for unprivileged group (men): {p_unprivi_positive}\")\n",
    "print(f\"Favourable outcomes for privileged group (men): {p_privi_positive}\")\n",
    "print(f\"Disparate Impact: {disparate_impact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fd38fae6-8156-4323-8e32-16eaf6f1bce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_val_pred_rf[privi_grp]== 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2437c6c4-4b20-49f9-af8a-e4e24bed4da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_val_pred_rf[privi_grp]== 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d222e6c-af3d-447f-99f0-591f9950293b",
   "metadata": {},
   "source": [
    "<h2>Fairness Analysis and Comparison of Fairness Metrics</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "afbfb42c-31d0-4b97-a5eb-47419a2b234e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact: 0.9494\n",
      "Equal Opportunity Difference: 0.0000\n",
      "Statistical Parity Difference: -0.0454\n",
      "Theil Index: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "\n",
    "df_val = pd.DataFrame(dataset_val.features, columns=dataset_val.feature_names)\n",
    "df_val['label'] = y_val_pred_rf\n",
    "\n",
    "#Convert the validation dataset to BinaryLabelDataset format for AIF360\n",
    "val_dataset_aif360 = BinaryLabelDataset(df=df_val,label_names=['label'],protected_attribute_names=['sex'])\n",
    "\n",
    "y_val_pred = y_val_pred_rf.reshape(-1, 1)\n",
    "\n",
    "val_dataset_pred = val_dataset_aif360.copy()\n",
    "val_dataset_pred.labels = y_val_pred\n",
    "\n",
    "#ClassificationMetric object\n",
    "metric = ClassificationMetric(val_dataset_aif360, val_dataset_pred, \n",
    "                              unprivileged_groups=[{'sex': 0}],  \n",
    "                              privileged_groups=[{'sex': 1}])  \n",
    "\n",
    "#Disparate Impact\n",
    "disparate_impact = metric.disparate_impact()\n",
    "print(f\"Disparate Impact: {disparate_impact:.4f}\")\n",
    "\n",
    "#Equal Opportunity Difference\n",
    "equal_opportunity_diff = metric.equal_opportunity_difference()\n",
    "print(f\"Equal Opportunity Difference: {equal_opportunity_diff:.4f}\")\n",
    "\n",
    "#Statistical Parity Difference\n",
    "statistical_parity_diff = metric.statistical_parity_difference()\n",
    "print(f\"Statistical Parity Difference: {statistical_parity_diff:.4f}\")\n",
    "\n",
    "#Theil Index\n",
    "theil_index = metric.between_group_generalized_entropy_index(alpha=1)\n",
    "print(f\"Theil Index: {theil_index:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bc51991a-383a-4a67-8cd6-ba4744075b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting BlackBoxAuditingNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\n",
      "     ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/2.6 MB 640.0 kB/s eta 0:00:05\n",
      "      --------------------------------------- 0.1/2.6 MB 812.7 kB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 0.3/2.6 MB 3.1 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 0.8/2.6 MB 4.6 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 1.3/2.6 MB 6.4 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.8/2.6 MB 7.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 2.5/2.6 MB 8.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.6/2.6 MB 8.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: aif360[DisparateImpactRemover] in c:\\users\\gouta\\anaconda3\\lib\\site-packages (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from aif360[DisparateImpactRemover]) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from aif360[DisparateImpactRemover]) (1.11.4)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from aif360[DisparateImpactRemover]) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from aif360[DisparateImpactRemover]) (1.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from aif360[DisparateImpactRemover]) (3.8.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from BlackBoxAuditing) (3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->aif360[DisparateImpactRemover]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->aif360[DisparateImpactRemover]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->aif360[DisparateImpactRemover]) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0->aif360[DisparateImpactRemover]) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0->aif360[DisparateImpactRemover]) (2.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from matplotlib->aif360[DisparateImpactRemover]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from matplotlib->aif360[DisparateImpactRemover]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from matplotlib->aif360[DisparateImpactRemover]) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from matplotlib->aif360[DisparateImpactRemover]) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from matplotlib->aif360[DisparateImpactRemover]) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from matplotlib->aif360[DisparateImpactRemover]) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from matplotlib->aif360[DisparateImpactRemover]) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gouta\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360[DisparateImpactRemover]) (1.16.0)\n",
      "Building wheels for collected packages: BlackBoxAuditing\n",
      "  Building wheel for BlackBoxAuditing (setup.py): started\n",
      "  Building wheel for BlackBoxAuditing (setup.py): finished with status 'done'\n",
      "  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394783 sha256=6bd49127745be4a2554c8c49c5653b1c21b9d62939293583eb5d860603a52b0e\n",
      "  Stored in directory: c:\\users\\gouta\\appdata\\local\\pip\\cache\\wheels\\c9\\8c\\03\\073e80e604151fb4cdc68b2e56a97f338d7723e4a4ab5e3823\n",
      "Successfully built BlackBoxAuditing\n",
      "Installing collected packages: BlackBoxAuditing\n",
      "Successfully installed BlackBoxAuditing-0.1.54\n"
     ]
    }
   ],
   "source": [
    "pip install aif360[DisparateImpactRemover] BlackBoxAuditing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e9751e-f3c2-47a2-ab3c-5019e377c958",
   "metadata": {},
   "source": [
    "<h2>4. Fairness Intervention</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b288bd-0a69-4ebd-bd60-595f585c2341",
   "metadata": {},
   "source": [
    "<h3>Pre-Processing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "40c04c00-ef34-484d-8f5f-368217f70adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact: 1.0139\n",
      "Equal Opportunity Difference: 0.0000\n",
      "Statistical Parity Difference: 0.0137\n"
     ]
    }
   ],
   "source": [
    "#DisparateImpactRemover\n",
    "\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "\n",
    "df_val = pd.DataFrame(dataset_train.features, columns=dataset_train.feature_names)\n",
    "df_val['label'] = y_train_pred_rf\n",
    "\n",
    "train_dataset_aif360 = BinaryLabelDataset(df=df_val,label_names=['label'],protected_attribute_names=['sex'])\n",
    "\n",
    "# Disparate Impact Remover (pre-processing)\n",
    "di_remover = DisparateImpactRemover(repair_level=1.0) \n",
    "train_dataset_transf = di_remover.fit_transform(train_dataset_aif360)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(train_dataset_transf.features, train_dataset_transf.labels.ravel())\n",
    "\n",
    "y_val_pred = model.predict(X_val_transformed)\n",
    "\n",
    "val_dataset_pred = val_dataset_aif360.copy()\n",
    "val_dataset_pred.labels = y_val_pred.reshape(-1, 1)\n",
    "\n",
    "metric = ClassificationMetric(val_dataset_aif360, val_dataset_pred, \n",
    "                              unprivileged_groups=[{'sex': 0}],  \n",
    "                              privileged_groups=[{'sex': 1}])  \n",
    "\n",
    "disparate_impact = metric.disparate_impact()\n",
    "equal_opportunity_diff = metric.equal_opportunity_difference()\n",
    "statistical_parity_diff = metric.statistical_parity_difference()\n",
    "\n",
    "\n",
    "#Disparate Impact\n",
    "print(f\"Disparate Impact: {disparate_impact:.4f}\")\n",
    "\n",
    "#Equal Opportunity Difference\n",
    "print(f\"Equal Opportunity Difference: {equal_opportunity_diff:.4f}\")\n",
    "\n",
    "#Statistical Parity Difference\n",
    "print(f\"Statistical Parity Difference: {statistical_parity_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ef1aa9dc-3591-4103-83e8-8e6b9b76ef9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>investment_as_income_percentage</th>\n",
       "      <th>residence_since</th>\n",
       "      <th>number_of_credits</th>\n",
       "      <th>people_liable_for</th>\n",
       "      <th>sex</th>\n",
       "      <th>status=A11</th>\n",
       "      <th>status=A12</th>\n",
       "      <th>status=A13</th>\n",
       "      <th>...</th>\n",
       "      <th>housing=A153</th>\n",
       "      <th>skill_level=A171</th>\n",
       "      <th>skill_level=A172</th>\n",
       "      <th>skill_level=A173</th>\n",
       "      <th>skill_level=A174</th>\n",
       "      <th>telephone=A191</th>\n",
       "      <th>telephone=A192</th>\n",
       "      <th>foreign_worker=A201</th>\n",
       "      <th>foreign_worker=A202</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>3959.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3577.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2515.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>10366.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2132.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1374.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  credit_amount  investment_as_income_percentage  residence_since  \\\n",
       "0     36.0         3959.0                              4.0              3.0   \n",
       "1      9.0         3577.0                              1.0              2.0   \n",
       "2     18.0         2515.0                              3.0              4.0   \n",
       "3     12.0         1995.0                              4.0              1.0   \n",
       "4     60.0        10366.0                              2.0              4.0   \n",
       "..     ...            ...                              ...              ...   \n",
       "795   10.0         2132.0                              2.0              3.0   \n",
       "796   18.0         1950.0                              4.0              1.0   \n",
       "797    6.0         1374.0                              1.0              2.0   \n",
       "798    6.0         1449.0                              1.0              2.0   \n",
       "799   18.0         1582.0                              4.0              4.0   \n",
       "\n",
       "     number_of_credits  people_liable_for  sex  status=A11  status=A12  \\\n",
       "0                  1.0                1.0  1.0         1.0         0.0   \n",
       "1                  1.0                2.0  1.0         0.0         0.0   \n",
       "2                  1.0                1.0  1.0         0.0         0.0   \n",
       "3                  1.0                1.0  1.0         0.0         1.0   \n",
       "4                  1.0                1.0  1.0         0.0         0.0   \n",
       "..                 ...                ...  ...         ...         ...   \n",
       "795                2.0                1.0  0.0         1.0         0.0   \n",
       "796                2.0                1.0  1.0         0.0         0.0   \n",
       "797                1.0                1.0  1.0         1.0         0.0   \n",
       "798                2.0                2.0  1.0         0.0         1.0   \n",
       "799                2.0                1.0  1.0         0.0         0.0   \n",
       "\n",
       "     status=A13  ...  housing=A153  skill_level=A171  skill_level=A172  \\\n",
       "0           0.0  ...           0.0               0.0               0.0   \n",
       "1           0.0  ...           0.0               0.0               0.0   \n",
       "2           0.0  ...           0.0               0.0               0.0   \n",
       "3           0.0  ...           0.0               0.0               0.0   \n",
       "4           0.0  ...           0.0               0.0               0.0   \n",
       "..          ...  ...           ...               ...               ...   \n",
       "795         0.0  ...           0.0               0.0               0.0   \n",
       "796         0.0  ...           0.0               0.0               0.0   \n",
       "797         0.0  ...           0.0               0.0               1.0   \n",
       "798         0.0  ...           0.0               0.0               0.0   \n",
       "799         0.0  ...           0.0               0.0               0.0   \n",
       "\n",
       "     skill_level=A173  skill_level=A174  telephone=A191  telephone=A192  \\\n",
       "0                 0.0               1.0             0.0             1.0   \n",
       "1                 1.0               0.0             1.0             0.0   \n",
       "2                 1.0               0.0             0.0             1.0   \n",
       "3                 1.0               0.0             1.0             0.0   \n",
       "4                 0.0               1.0             0.0             1.0   \n",
       "..                ...               ...             ...             ...   \n",
       "795               1.0               0.0             1.0             0.0   \n",
       "796               1.0               0.0             0.0             1.0   \n",
       "797               0.0               0.0             0.0             1.0   \n",
       "798               1.0               0.0             1.0             0.0   \n",
       "799               1.0               0.0             1.0             0.0   \n",
       "\n",
       "     foreign_worker=A201  foreign_worker=A202  label  \n",
       "0                    1.0                  0.0    1.0  \n",
       "1                    0.0                  1.0    1.0  \n",
       "2                    1.0                  0.0    1.0  \n",
       "3                    1.0                  0.0    1.0  \n",
       "4                    1.0                  0.0    1.0  \n",
       "..                   ...                  ...    ...  \n",
       "795                  0.0                  1.0    1.0  \n",
       "796                  1.0                  0.0    1.0  \n",
       "797                  1.0                  0.0    1.0  \n",
       "798                  1.0                  0.0    1.0  \n",
       "799                  1.0                  0.0    1.0  \n",
       "\n",
       "[800 rows x 58 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a41fb2-d655-43f2-902e-dc0c8b793fb5",
   "metadata": {},
   "source": [
    "<h3>In-Processing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "8730fbd2-eb14-49bb-ba62-aa5371187181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.inprocessing import MetaFairClassifier\n",
    "\n",
    "\n",
    "df_train = pd.DataFrame(dataset_train.features, columns=dataset_train.feature_names)\n",
    "df_train['label'] = dataset_train.labels\n",
    "\n",
    "df_val = pd.DataFrame(dataset_val.features, columns=dataset_val.feature_names)\n",
    "df_val['label'] = dataset_val.labels\n",
    "\n",
    "train_dataset_aif360 = BinaryLabelDataset(df=df_train, label_names=['label'], protected_attribute_names=['sex'], favorable_label=1, unfavorable_label=0)\n",
    "val_dataset_aif360 = BinaryLabelDataset(df=df_val, label_names=['label'], protected_attribute_names=['sex'], favorable_label=1, unfavorable_label=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_dataset_aif360.features = scaler.fit_transform(train_dataset_aif360.features)  \n",
    "val_dataset_aif360.features = scaler.transform(val_dataset_aif360.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "73156cb4-10ce-4c98-941a-ce91a9dff559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Apply MetaFairClassifier (in-processing)\n",
    "meta_fair = MetaFairClassifier(sensitive_attr='sex', type='fdr', tau=0.6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "6553ad68-3453-4f9e-a597-4f8f49d75dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gouta\\anaconda3\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\celisMeta\\FalseDiscovery.py:31: RuntimeWarning: invalid value encountered in divide\n",
      "  prob_y_1 = (prob_1_1 + prob_1_0) / total\n",
      "C:\\Users\\gouta\\anaconda3\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\celisMeta\\FalseDiscovery.py:32: RuntimeWarning: invalid value encountered in divide\n",
      "  prob_z_0 = (prob_m1_0 + prob_1_0) / total\n",
      "C:\\Users\\gouta\\anaconda3\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\celisMeta\\FalseDiscovery.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  prob_z_1 = (prob_m1_1 + prob_1_1) / total\n",
      "C:\\Users\\gouta\\anaconda3\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\celisMeta\\FalseDiscovery.py:35: RuntimeWarning: invalid value encountered in divide\n",
      "  probc_m1_0 = prob_m1_0 / total\n",
      "C:\\Users\\gouta\\anaconda3\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\celisMeta\\FalseDiscovery.py:36: RuntimeWarning: invalid value encountered in divide\n",
      "  probc_m1_1 = prob_m1_1 / total\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[330], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m meta_fair\u001b[38;5;241m.\u001b[39mfit(train_dataset_aif360)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\aif360\\algorithms\\transformer.py:27\u001b[0m, in \u001b[0;36maddmetadata.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 27\u001b[0m     new_dataset \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_dataset, Dataset):\n\u001b[0;32m     29\u001b[0m         new_dataset\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m new_dataset\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\meta_fair_classifier.py:66\u001b[0m, in \u001b[0;36mMetaFairClassifier.fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m     59\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(dataset\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;241m==\u001b[39m dataset\u001b[38;5;241m.\u001b[39mfavorable_label,\n\u001b[0;32m     60\u001b[0m                    \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     61\u001b[0m x_control_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[0;32m     62\u001b[0m         np\u001b[38;5;241m.\u001b[39misin(dataset\u001b[38;5;241m.\u001b[39mprotected_attributes[:, sens_idx],\n\u001b[0;32m     63\u001b[0m                 dataset\u001b[38;5;241m.\u001b[39mprivileged_protected_attributes[sens_idx]),\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mgetModel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtau, x_train, y_train,\n\u001b[0;32m     67\u001b[0m     x_control_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\celisMeta\\General.py:99\u001b[0m, in \u001b[0;36mGeneral.getModel\u001b[1;34m(self, tau, X, y, sens, random_state)\u001b[0m\n\u001b[0;32m     96\u001b[0m samples \u001b[38;5;241m=\u001b[39m dist_x\u001b[38;5;241m.\u001b[39mrvs(size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)  \u001b[38;5;66;03m# TODO: why 20?\u001b[39;00m\n\u001b[0;32m     97\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradientDescent(dist, a, b, samples, z_1)\n\u001b[1;32m---> 99\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetValueForX(dist, a, b, params, z_1, X)\n\u001b[0;32m    100\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(t \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    102\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\celisMeta\\FalseDiscovery.py:18\u001b[0m, in \u001b[0;36mFalseDiscovery.getValueForX\u001b[1;34m(self, dist, a, b, params, z_prior, x, return_probs)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetValueForX\u001b[39m(\u001b[38;5;28mself\u001b[39m, dist, a, b, params, z_prior, x, return_probs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 18\u001b[0m     u_1, u_2, l_1, l_2 \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m     19\u001b[0m     z_0, z_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mz_prior, z_prior\n\u001b[0;32m     21\u001b[0m     pos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(x))\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "meta_fair.fit(train_dataset_aif360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "311ace1d-5db7-4345-9938-c07ed52bd3ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MetaFairClassifier' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[324], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 5: Use the MetaFairClassifier to make predictions on the validation set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m val_dataset_pred \u001b[38;5;241m=\u001b[39m meta_fair\u001b[38;5;241m.\u001b[39mpredict(val_dataset_aif360)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 6: Set the predicted labels in the validation dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m val_dataset_pred\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m val_dataset_pred\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\aif360\\algorithms\\transformer.py:27\u001b[0m, in \u001b[0;36maddmetadata.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 27\u001b[0m     new_dataset \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_dataset, Dataset):\n\u001b[0;32m     29\u001b[0m         new_dataset\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m new_dataset\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\aif360\\algorithms\\inprocessing\\meta_fair_classifier.py:82\u001b[0m, in \u001b[0;36mMetaFairClassifier.predict\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset):\n\u001b[0;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Obtain the predictions for the provided dataset using the learned\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    classifier model.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m        BinaryLabelDataset: Transformed dataset.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(dataset\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[0;32m     84\u001b[0m     pred_dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     85\u001b[0m     pred_dataset\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m (t \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MetaFairClassifier' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "\n",
    "val_dataset_pred = meta_fair.predict(val_dataset_aif360)\n",
    "val_dataset_pred.labels = val_dataset_pred.labels.reshape(-1, 1)\n",
    "\n",
    "metric = ClassificationMetric(val_dataset_aif360, val_dataset_pred, \n",
    "                              unprivileged_groups=[{'sex': 0}], \n",
    "                              privileged_groups=[{'sex': 1}])   \n",
    "\n",
    "disparate_impact = metric.disparate_impact()\n",
    "equal_opportunity_diff = metric.equal_opportunity_difference()\n",
    "statistical_parity_diff = metric.statistical_parity_difference()\n",
    "\n",
    "print(f\"Disparate Impact: {disparate_impact}\")\n",
    "print(f\"Equal Opportunity Difference: {equal_opportunity_diff}\")\n",
    "print(f\"Statistical Parity Difference: {statistical_parity_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcaa46-8699-4ab3-a71b-d802fab46822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38094e7b-372e-4d46-ab79-207ac0a564bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63b12888-1b9e-4e52-925c-d75ae3845c97",
   "metadata": {},
   "source": [
    "<h3>Post-Processing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "0438dde3-6795-423f-a1dc-ff7c8448857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Impact: 0.9494\n",
      "Equal Opportunity Difference: 0.0000\n",
      "Statistical Parity Difference: -0.0454\n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing\n",
    "\n",
    "\n",
    "df_val = pd.DataFrame(dataset_val.features, columns=dataset_val.feature_names)\n",
    "df_val['label'] = dataset_val.labels\n",
    "val_dataset_aif360 = BinaryLabelDataset(df=df_val, label_names=['label'], protected_attribute_names=['sex'])\n",
    "\n",
    "y_val_pred = y_val_pred_rf.reshape(-1, 1)\n",
    "val_dataset_pred = val_dataset_aif360.copy()\n",
    "val_dataset_pred.labels = y_val_pred\n",
    "\n",
    "calibrated_eq_odds = CalibratedEqOddsPostprocessing(unprivileged_groups=[{'sex': 0}], privileged_groups=[{'sex': 1}],cost_constraint='fnr')\n",
    "\n",
    "calibrated_eq_odds = calibrated_eq_odds.fit(val_dataset_aif360, val_dataset_pred)\n",
    "\n",
    "val_dataset_pred = calibrated_eq_odds.predict(val_dataset_pred)\n",
    "\n",
    "metric = ClassificationMetric(val_dataset_aif360, val_dataset_pred, \n",
    "                                         unprivileged_groups=[{'sex': 0}], privileged_groups=[{'sex': 1}])\n",
    "\n",
    "disparate_impact = metric.disparate_impact()\n",
    "print(f\"Disparate Impact: {disparate_impact:.4f}\")\n",
    "\n",
    "equal_opportunity_diff = metric.equal_opportunity_difference()\n",
    "print(f\"Equal Opportunity Difference: {equal_opportunity_diff:.4f}\")\n",
    "\n",
    "statistical_parity_diff = metric.statistical_parity_difference()\n",
    "print(f\"Statistical Parity Difference: {statistical_parity_diff:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a23575-4536-4db4-be79-ecc11280e6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239a87da-2c99-4722-ab9f-499f0a2240b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74f425-fb11-483f-9533-c793587de977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348960b8-cc86-48ff-98a1-05a428e00e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1414b7c1-ec5a-4c0b-87bb-0b11bc271d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Citations\n",
    "How to use wget to download files in windows--> https://www.tomshardware.com/how-to/use-wget-download-files-command-line\n",
    "XGBoost or SVM? --> https://datascience.stackexchange.com/questions/25883/xgboost-classification-probabilities-higher-than-rf-or-svm\n",
    "How to convert validation dataset to BinaryLabelDataset format for AIF360 --> https://chatgpt.com/share/66fe619f-b2b0-8001-a5cf-6976c911e918\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4d590f-5231-40db-8ef8-8ebb3336a946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4866e15b-948b-48a9-b982-02b2a480e66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d436b3f-3b55-41cf-b84b-9ef8ee77e7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
